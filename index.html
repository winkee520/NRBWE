
<!doctype html>
<html lang="en">

<head>
  <meta name="google-site-verification" content="ftFOlJETX-2KNjaPh8W6s8lhigItRuu9fOmjHZZ0nY0" />
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <title>VisualTTS</title>
</head>
<style type="text/css">
  table {
    width: 100%;
    table-layout: fixed;
  }

  audio {
    width: 100%;
  }

  thead>tr>th:first-child {
    width: 96px;
  }

  @media (max-width: 767px) {
    .big-screen {
      display: none;
    }
  }

  @media (min-width: 767px) {
    .small-screen {
      display: none;
    }
  }
</style>




<body>
  <header class="header">
    <div class="jumbotron bg-secondary text-center">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-md-12">
 
            <h1><a class="text-light">A Neural Codec Approach for Noise-Robust Bandwidth Expansion </h1><br>   
             <font size=5><span style="color:#FFFFFF"> Anonymous submission to INTERSPEECH 2025 <br></font>
		 </a>  
            <p>
              <div class="row">
              </div>
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </header>
  <main>
    <div class="container">
      <div class="row" id="result">
        <div class="col-md-12">
        	<h4>Abstract</h4>  
          Neural audio codec technology has recently attracted significant attention in various speech processing tasks due to its efficient quantized latent features. In this work, we introduce a novel approach that leverages a pre-trained neural codec network to perform both speech denoising and bandwidth expansion simultaneously. Specifically, we design a conformer-based deep neural network to predict clean codebook indices, which are then used by the pre-trained audio codec model to generate enhanced and bandwidth expanded audio. We investigate several strategies for generating the clean indices and compare our approach with state-of-the-art methods on the Valentini-Botinhao noisy test set. Experimental results demonstrate that our method achieves performance comparable to leading approaches in noise-robust bandwidth expansion tasks while offering promising improvements in the quality and intelligibility of narrow-band signals.<br>
<br>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center;">
  <div style="text-align: center;margin-left: 40px;">
    <img src="overview.drawio.png" width="860" height="260">
    <p> <br><br>System overview of the proposed system. The system contains 2 parts: Descript Audio Codec (DAC) and clean token
      predictor. DAC is consisted of DAC Encoder, Residual Vector quantization (RVQ) and DAC Decoder, and clean token predictor has
      multiple Conformer layers and Multi-head linear layers.</p>
  </div>
</div>
<br><br>

      <h4>Test Datasets</h4>
      <b>Valentini-Botinhao [1]</b>: A synthetic data set. <br>

      <br><br>
    <h4> Audio Samples </h4>
    <hr class="hr_line">
    <h5>Valentini-Botinhao dataset</h5>
    <table class="table ">
      <thead>
          <tr>
              <th>Samples</th>
              <th>Noisy</th>
              <th>proposed</th>
              <th>Clean</th>
          </tr>
      </thead>
      <tbody>
        <tr> <td> Sample 1 </td>
          <td><audio controls=""><source src="Noisy/p257_126.wav"></audio></td>
          <td><audio controls=""><source src="Proposed/p257_126.wav"></audio></td>
          <td><audio controls=""><source src="Clean/p257_126.wav"></audio></td>
        </tr>
        <tr> <td> Sample 2 </td>
          <td><audio controls=""><source src="Noisy/p232_110.wav"></audio></td>
          <td><audio controls=""><source src="Proposed/p232_110.wav"></audio></td>
          <td><audio controls=""><source src="Clean/p232_110.wav"></audio></td>
        </tr>
        <tr> <td> Sample 3 </td>
          <td><audio controls=""><source src="Noisy/p232_137.wav"></audio></td>
          <td><audio controls=""><source src="Proposed/p232_137.wav"></audio></td>
          <td><audio controls=""><source src="Clean/p232_137.wav"></audio></td>
        </tr>
        <tr> <td> Sample 4 </td>
          <td><audio controls=""><source src="Noisy/p232_362.wav"></audio></td>
          <td><audio controls=""><source src="Proposed/p232_362.wav"></audio></td>
          <td><audio controls=""><source src="Clean/p232_362.wav"></audio></td>
        </tr>
        <tr> <td> Sample 5 </td>
          <td><audio controls=""><source src="Noisy/p257_431.wav"></audio></td>
          <td><audio controls=""><source src="Proposed/p257_431.wav"></audio></td>
          <td><audio controls=""><source src="Clean/p257_431.wav"></audio></td>
        </tr>
        </tr>
    </tbody>
</table>
<hr class="hr_line">
<h5>Real recordings</h5>
<table class="table ">
  <thead>
      <tr>
          <th>Samples</th>
          <th>Noisy</th>
          <th>proposed</th>
      </tr>
  </thead>
  <tbody>
    <tr> <td> Sample 1 </td>
      <td><audio controls=""><source src="Noisy/clinton-cut_0-0_0-11.wav"></audio></td>
      <td><audio controls=""><source src="Proposed/clinton-cut_0-0_0-11.wav"></audio></td>
    </tr>
    <tr> <td> Sample 2 </td>
      <td><audio controls=""><source src="Noisy/truman-cut_0-21_0-35.wav"></audio></td>
      <td><audio controls=""><source src="Proposed/truman-cut_0-21_0-35.wav"></audio></td>
    </tr>
    <tr> <td> Sample 3 </td>
      <td><audio controls=""><source src="Noisy/a11_01.wav"></audio></td>
      <td><audio controls=""><source src="Proposed/a11_01.wav"></audio></td>
    </tr>
    <tr> <td> Sample 4 </td>
      <td><audio controls=""><source src="Noisy/a11_02.wav"></audio></td>
      <td><audio controls=""><source src="Proposed/a11_02.wav"></audio></td>
    </tr>
    </tr>
</tbody>
</table>
<hr class="hr_line">
<h4> References </h4>
[1] C. Valentini-Botinhao et al., “Noisy speech database for training speech enhancement algorithms and tts models,” University of Ed- inburgh. School of Informatics. Centre for Speech Technology Re- search (CSTR), 2017. <br>
<br>
        
        
</div>
</div>